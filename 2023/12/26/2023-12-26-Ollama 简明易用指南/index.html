<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/imgs/logo.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/imgs/32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/imgs/16.png">
  <link rel="mask-icon" href="/imgs/logo.png" color="#222">
  <meta name="google-site-verification" content="dJfRF5_6EbT_bJo2wTKbSXTDmNaOTqDGRDMcU6ylduk">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"ghyghoo8.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":true,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"livere","storage":true,"lazyload":false,"nav":null,"activeClass":"livere"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="引言在过去的几个季度里，大语言模型（LLM）的平民化运动一直在快速发展，从最初的 Meta 发布 Llama 2 到如今，开源社区以不可阻挡之势适配、进化、落地。LLM已经从昂贵的GPU运行转变为可以在大多数消费级计算机上运行推理的应用，通称为本地大模型。 然而，本地大模型的推理需要相当大的显存，对于16位浮点精度（FP16）的模型，显存需求约为模型参数量的两倍。这使得运行大模型成为对普通家用计">
<meta property="og:type" content="article">
<meta property="og:title" content="拥抱本地大模型：Ollama 简明易用指南">
<meta property="og:url" content="https://ghyghoo8.github.io/2023/12/26/2023-12-26-Ollama%20%E7%AE%80%E6%98%8E%E6%98%93%E7%94%A8%E6%8C%87%E5%8D%97/index.html">
<meta property="og:site_name" content="G8空间">
<meta property="og:description" content="引言在过去的几个季度里，大语言模型（LLM）的平民化运动一直在快速发展，从最初的 Meta 发布 Llama 2 到如今，开源社区以不可阻挡之势适配、进化、落地。LLM已经从昂贵的GPU运行转变为可以在大多数消费级计算机上运行推理的应用，通称为本地大模型。 然而，本地大模型的推理需要相当大的显存，对于16位浮点精度（FP16）的模型，显存需求约为模型参数量的两倍。这使得运行大模型成为对普通家用计">
<meta property="og:locale">
<meta property="article:published_time" content="2023-12-25T16:00:00.000Z">
<meta property="article:modified_time" content="2025-03-15T07:37:17.098Z">
<meta property="article:author" content="ghyghoo8">
<meta property="article:tag" content="大模型部署">
<meta property="article:tag" content="ai">
<meta property="article:tag" content="ollama">
<meta property="article:tag" content="教程">
<meta property="article:tag" content="指南">
<meta property="article:tag" content="入门">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://ghyghoo8.github.io/2023/12/26/2023-12-26-Ollama%20%E7%AE%80%E6%98%8E%E6%98%93%E7%94%A8%E6%8C%87%E5%8D%97/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>拥抱本地大模型：Ollama 简明易用指南 | G8空间</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start --><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7923526446101866" crossorigin="anonymous"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/sakana-widget@2.7.0/lib/sakana.min.css" /><style>#sakana-widget{position:fixed;bottom:0;left:0;}</style><!-- hexo injector head_end end --><link rel="alternate" href="/atom.xml" title="G8空间" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">G8空间</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">ghyghoo8的沉淀小碎</p>
      <a>
        <img class="custom-logo-image" src="/imgs/IMG_0001.PNG" alt="G8空间">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-guestbook">

    <a href="/guestbook" rel="section"><i class="fa fa-comment fa-fw"></i>guestbook</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL2doeWdob284" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://ghyghoo8.github.io/2023/12/26/2023-12-26-Ollama%20%E7%AE%80%E6%98%8E%E6%98%93%E7%94%A8%E6%8C%87%E5%8D%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ghyghoo8">
      <meta itemprop="description" content="碎了一地...o(*￣︶￣*)o...">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="G8空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          拥抱本地大模型：Ollama 简明易用指南
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-12-26 00:00:00" itemprop="dateCreated datePublished" datetime="2023-12-26T00:00:00+08:00">2023-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-03-15 15:37:17" itemprop="dateModified" datetime="2025-03-15T15:37:17+08:00">2025-03-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/llm/" itemprop="url" rel="index"><span itemprop="name">llm</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <hr>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>在过去的几个季度里，大语言模型（LLM）的平民化运动一直在快速发展，从最初的 Meta 发布 Llama 2 到如今，开源社区以不可阻挡之势适配、进化、落地。LLM已经从昂贵的GPU运行转变为可以在大多数消费级计算机上运行推理的应用，通称为本地大模型。</p>
<p>然而，本地大模型的推理需要相当大的显存，对于16位浮点精度（FP16）的模型，显存需求约为模型参数量的两倍。这使得运行大模型成为对普通家用计算机硬件规格的挑战。为了解决这个问题，模型量化技术应运而生，将权重参数的精度压缩为4位整数精度，大幅减小了显存需求。</p>
<p>在这一背景下，llama.cpp项目通过C&#x2F;C++重写了推理代码，避免了PyTorch引入的复杂依赖，并提供了更广泛的硬件支持，包括纯CPU推理、Apple Silicon等。然而，llama.cpp的使用仍然对用户有一定的门槛，需要获取模型权重、克隆项目代码、执行模型量化、设置环境变量等。</p>
<p>直到Ollama的出现，一个简明易用的本地大模型运行框架，为用户提供了更便捷的方式在个人电脑上运行大模型。</p>
<h3 id="快速上手"><a href="#快速上手" class="headerlink" title="快速上手"></a>快速上手</h3><p>Ollama的安装非常简单，macOS用户只需在官网下载安装包并运行，而Windows用户则可以通过WSL 2以Linux方式用命令进行安装。同时，熟悉Docker的用户也可以直接使用其官方镜像。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">% curl https://ollama.ai/install.sh | sh</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>安装完成后，通过运行 ollama –version 命令检查版本，确认安装成功后即可通过 ollama pull 命令从在线模型库下载模型。例如，下载中文微调过的Llama2-Chinese 7B模型的4-bit量化版本：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">% ollama pull llama2-chinese</span><br></pre></td></tr></table></figure>

<p>下载完成后，使用 ollama run 命令即可运行模型并进行推理，支持单条输入或对话模式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 单条输入</span><br><span class="line">% ollama run llama2-chinese &quot;天空为什么是蓝色的？&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 对话模式</span><br><span class="line">% ollama run llama2-chinese</span><br><span class="line">&gt;&gt;&gt; /?</span><br><span class="line">Available Commands:</span><br><span class="line">  /set         Set session variables</span><br><span class="line">  /show        Show model information</span><br><span class="line">  /bye         Exit</span><br><span class="line">  /?, /help    Help for a command</span><br><span class="line"></span><br><span class="line">Use &quot;&quot;&quot; to begin a multi-line message.</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; 天空为什么是蓝色的？</span><br><span class="line"></span><br><span class="line">这个问题是一个常见的争议。有一些科学家认为天空的蓝色可以被解释为雾和云层中的微小碎片反射出来的光色，而其他人则认为这是由于地球自身温度的影响。目前还没这个问题是一个常见的争议。有一些科学家认为天空的蓝色可以被解释为雾和云层中的微小碎片反射出来的光色，而其他人则认为这是由于地球自身温度的影响。目前还没有一个公认的解释。</span><br></pre></td></tr></table></figure>


<h3 id="套壳玩法"><a href="#套壳玩法" class="headerlink" title="套壳玩法"></a>套壳玩法</h3><p>尽管Ollama为用户带来了便利，但命令行形式仍然对一些用户来说不够友好。为此，Ollama提供了一系列周边工具，包括Web界面、桌面应用、终端工具等。其中，Ollama GUI的选择多样，包括Web版本、终端TUI版本（oterm）以及Raycast插件等，以满足用户不同的使用偏好。<br><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ptb3JnYW5jYS9vbGxhbWE/dGFiPXJlYWRtZS1vdi1maWxlI2NvbW11bml0eS1pbnRlZ3JhdGlvbnM=">传送门<i class="fa fa-external-link-alt"></i></span></p>
<h3 id="进阶玩法"><a href="#进阶玩法" class="headerlink" title="进阶玩法"></a>进阶玩法</h3><h4 id="更换模型"><a href="#更换模型" class="headerlink" title="更换模型"></a>更换模型</h4><p>Ollama支持用户自定义系统提示词和调整推理温度等参数。用户可以根据自己的需求选择不同版本的模型，如13B版本，只需在命令中添加对应标签：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">% ollama run llama2-chinese:13b &quot;天空为什么是蓝色的？&quot;</span><br><span class="line"></span><br><span class="line">天空是由大气层和太阳光的散射而成的蓝色。</span><br><span class="line"></span><br><span class="line">在日出之前，我们看到的天空是紫色或彩虹色，这是因为太阳光从海平面反射回来时，会被大气中的二氧化碳和水分子散射成蓝色、紫色或彩虹色。</span><br><span class="line"></span><br><span class="line">而在日出之后，天空变成了灰色，这是由于太阳光从大气中被阻挡，并且不再有足够的反射来给天空增加蓝色。</span><br><span class="line"></span><br><span class="line">当我们看到天空时，它的颜色是由于太阳光与大气中的物质相互作用而形成的。这些物质包括水、二氧化碳和其他气体，以及微小的冰片和沙塵。</span><br><span class="line"></span><br><span class="line">当我们看到天空变成了晚上时，天空会逐渐变得更加深蓝，这是由于太阳光在大气中传播，同时也因为大气层的结构。</span><br></pre></td></tr></table></figure>


<h4 id="图片支持"><a href="#图片支持" class="headerlink" title="图片支持"></a>图片支持</h4><p>除了纯语言大模型，Ollama还从0.1.15版本开始提供了对视觉模型的支持。用户只需在提示中添加本地图片路径即可进行图像文本推理。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">% ollama run llava</span><br><span class="line">&gt;&gt;&gt; What does the text in this image say? /Users/mchiang/Downloads/image.png </span><br><span class="line">Added image &#x27;/Users/mchiang/Downloads/image.png&#x27;</span><br><span class="line"></span><br><span class="line">The text in this image says &quot;The Ollamas.&quot;</span><br></pre></td></tr></table></figure>

<h4 id="自定义系统提示词"><a href="#自定义系统提示词" class="headerlink" title="自定义系统提示词"></a>自定义系统提示词</h4><p>Ollama允许用户自定义系统提示词，提高模型的个性化。用户可以通过前端工具或直接调用API传入系统提示词选项进行配置。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:11434/api/chat -d &#x27;&#123;</span><br><span class="line">  &quot;model&quot;: &quot;llama2-chinese:13b&quot;,</span><br><span class="line">  &quot;messages&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;role&quot;: &quot;system&quot;,</span><br><span class="line">      &quot;content&quot;: &quot;以海盗的口吻简单作答。&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">      &quot;content&quot;: &quot;天空为什么是蓝色的？&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;stream&quot;: false</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>


<h4 id="更多选项"><a href="#更多选项" class="headerlink" title="更多选项"></a>更多选项</h4><p>Ollama的ModelFile提供了更多自定义的空间，包括系统提示词、对话模板、模型推理温度、上下文窗口长度等参数均可自行设置，适合进阶使用者。</p>
<p>在创建前，通过 <code>show --modelfile</code> 命令可以查看现有模型的 ModelFile 内容，作为参考：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">% ollama show --modelfile llama2-chinese:13b</span><br><span class="line"># Modelfile generated by &quot;ollama show&quot;</span><br><span class="line"># To build a new Modelfile based on this one, replace the FROM line with:</span><br><span class="line"># FROM llama2-chinese:13b</span><br><span class="line"></span><br><span class="line">FROM ~/.ollama/models/blobs/sha256:8359bebea988186aa6a947d55d67941fede5044d02e0ab2078f5cc0dcf357831</span><br><span class="line">TEMPLATE &quot;&quot;&quot;&#123;&#123; .System &#125;&#125;</span><br><span class="line">Name: &#123;&#123; .Prompt &#125;&#125;</span><br><span class="line">Assistant:</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">PARAMETER stop &quot;Name:&quot;</span><br><span class="line">PARAMETER stop &quot;Assistant:&quot;</span><br></pre></td></tr></table></figure>
<p>以自定义系统提示词并修改推理温度参数为例，应构建如下格式的 ModelFile：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FROM llama2-chinese:13b</span><br><span class="line"></span><br><span class="line">SYSTEM &quot;以海盗的口吻作答。&quot;</span><br><span class="line">PARAMETER temperature 0.1</span><br></pre></td></tr></table></figure>
<p>然后使用 create 命令进行创建，新的模型会沿用原有模型的权重文件和未作调整的选项参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama create llama2-chinese-pirate -f ~/path/to/ModelFile</span><br></pre></td></tr></table></figure>
<p>从而得到了属于自己的本地模型。</p>
<h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>Ollama的出现使得本地大模型的运行变得更加简单快捷。尽管相较于普通应用软件，Ollama的使用体验可能仍有提升空间，但与数月前相比，其进步巨大。称Ollama为AI技术平民化的贡献并不为过，它为更多人以最简单快速的方式在本地运行大模型提供了可能。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/" rel="tag"># 大模型部署</a>
              <a href="/tags/ai/" rel="tag"># ai</a>
              <a href="/tags/ollama/" rel="tag"># ollama</a>
              <a href="/tags/%E6%95%99%E7%A8%8B/" rel="tag"># 教程</a>
              <a href="/tags/%E6%8C%87%E5%8D%97/" rel="tag"># 指南</a>
              <a href="/tags/%E5%85%A5%E9%97%A8/" rel="tag"># 入门</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/12/04/2023-12-04-css3%E5%AE%9E%E7%8E%B0%E8%AF%AD%E9%9F%B3%E5%A3%B0%E6%B3%A2/" rel="prev" title="CSS3实现语音声波">
      <i class="fa fa-chevron-left"></i> CSS3实现语音声波
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/01/08/2024-01-08-%E6%8E%A2%E7%B4%A2RAG%E5%B7%A5%E7%A8%8B%EF%BC%9A%E5%BC%80%E5%90%AF%E5%A4%A7%E8%A7%84%E6%A8%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9F%A5%E8%AF%86%E6%A3%80%E7%B4%A2%E7%9A%84%E9%9D%A9%E6%96%B0%E4%B9%8B%E6%97%85/" rel="next" title="探索RAG工程：开启大规模语言模型与知识检索的革新之旅">
      探索RAG工程：开启大规模语言模型与知识检索的革新之旅 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC81NDA1OS8zMDUzMQ=="></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%95%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">引言</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B"><span class="nav-number">2.</span> <span class="nav-text">快速上手</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A5%97%E5%A3%B3%E7%8E%A9%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">套壳玩法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%9B%E9%98%B6%E7%8E%A9%E6%B3%95"><span class="nav-number">4.</span> <span class="nav-text">进阶玩法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9B%B4%E6%8D%A2%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.1.</span> <span class="nav-text">更换模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E7%89%87%E6%94%AF%E6%8C%81"><span class="nav-number">4.2.</span> <span class="nav-text">图片支持</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B3%BB%E7%BB%9F%E6%8F%90%E7%A4%BA%E8%AF%8D"><span class="nav-number">4.3.</span> <span class="nav-text">自定义系统提示词</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9B%B4%E5%A4%9A%E9%80%89%E9%A1%B9"><span class="nav-number">4.4.</span> <span class="nav-text">更多选项</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%93%E8%AF%AD"><span class="nav-number">5.</span> <span class="nav-text">结语</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">ghyghoo8</p>
  <div class="site-description" itemprop="description">碎了一地...o(*￣︶￣*)o...</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">22</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">37</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ghyghoo8</span>
</div>
  <div class="powered-by">Powered by <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl theme-link" data-url="aHR0cHM6Ly9waXNjZXMudGhlbWUtbmV4dC5vcmc=">NexT.Pisces</span>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.1.0/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>

<!-- hexo injector body_end start -->
<script src="/js/bot.js"></script>
<div id="sakana-widget"></div><script>
      function initSakanaWidget() {
        // 默认自走模式
        new SakanaWidget().mount('#sakana-widget').triggetAutoMode();
      }
    </script><script
      async
      onload="initSakanaWidget()"
      src="https://cdn.jsdelivr.net/npm/sakana-widget@2.7.0/lib/sakana.min.js"
    ></script><!-- hexo injector body_end end --></body>
</html>
